{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshhn/MinutesOfMeeting/blob/pnd/SSSMoM_Git_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d628dca-9854-48b6-a99f-cb89045be05f",
      "metadata": {
        "id": "6d628dca-9854-48b6-a99f-cb89045be05f"
      },
      "outputs": [],
      "source": [
        "# !pip install openai\n",
        "# !pip install python-docx\n",
        "# !pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "397fd9d7-7406-4d60-9eca-d0563a359149",
      "metadata": {
        "id": "397fd9d7-7406-4d60-9eca-d0563a359149",
        "outputId": "c584a7c0-b622-4a9c-acbc-95881003cd5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path  # For more platform-independent path handling\n",
        "\n",
        "# Option 1: Using a string for the path\n",
        "dotenv_path = r\"C:\\Users\\dell\\Downloads\\OpenApi.env\"\n",
        "load_dotenv(dotenv_path=dotenv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7d48348-bfc2-4bb2-a8a6-284a62e15473",
      "metadata": {
        "id": "b7d48348-bfc2-4bb2-a8a6-284a62e15473",
        "outputId": "04bb3543-d645-4610-d307-a6381e34168b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your API key is: 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\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(dotenv_path=dotenv_path)\n",
        "\n",
        "# Let's say you have a variable named 'API_KEY' in your .env file\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Now you can use the api_key variable in your script\n",
        "print(f\"Your API key is: {api_key}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1059d796-a32f-45ce-b6a5-cc47dd2f6e10",
      "metadata": {
        "id": "1059d796-a32f-45ce-b6a5-cc47dd2f6e10"
      },
      "outputs": [],
      "source": [
        "# from openai import OpenAI\n",
        "# def transcribe_audio(audio_file_path, openai_client=None):\n",
        "#     with open(audio_file_path, 'rb') as audio_file:\n",
        "#         transcription = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "#     return transcription['text']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc552e94-fd52-48c2-8fb6-01617dc9ecca",
      "metadata": {
        "id": "dc552e94-fd52-48c2-8fb6-01617dc9ecca"
      },
      "outputs": [],
      "source": [
        "# # transcription.py\n",
        "# import os\n",
        "# from openai import OpenAI\n",
        "\n",
        "# def transcribe_audio(audio_file_path, openai_client=None):\n",
        "#     \"\"\"\n",
        "#     Transcribes an audio file using OpenAI's Whisper API.\n",
        "\n",
        "#     Args:\n",
        "#         audio_file_path (str): The path to the audio file.\n",
        "#         openai_client (openai.OpenAI, optional): An OpenAI client instance.\n",
        "#                                                   If None, a new client will be created.\n",
        "\n",
        "#     Returns:\n",
        "#         str: The transcribed text.\n",
        "#     \"\"\"\n",
        "#     if openai_client is None:\n",
        "#         client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
        "#     else:\n",
        "#         client = openai_client\n",
        "\n",
        "#     try:\n",
        "#         with open(audio_file_path, \"rb\") as audio_file:\n",
        "#             transcript = client.audio.transcriptions.create(\n",
        "#                 model=\"whisper-1\",\n",
        "#                 file=audio_file\n",
        "#             )\n",
        "#         return transcript.text\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error during transcription: {e}\")\n",
        "#         return None\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     # Example usage (for testing the transcription function)\n",
        "#     load_dotenv()\n",
        "#     openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "#     if not openai_api_key:\n",
        "#         print(\"OPENAI_API_KEY not found in .env file.\")\n",
        "#     else:\n",
        "#         audio_path = r\"C:\\Users\\dell\\Downloads\\newMeeting.mp3\"  # Replace with your audio file\n",
        "#         if os.path.exists(audio_path):\n",
        "#             transcription_text = transcribe_audio(audio_path)\n",
        "#             if transcription_text:\n",
        "#                 print(\"Transcription:\")\n",
        "#                 print(transcription_text)\n",
        "#         else:\n",
        "#             print(f\"Audio file not found at: {audio_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca269ef0-1fcb-4250-99cd-e87aeb832fd1",
      "metadata": {
        "id": "ca269ef0-1fcb-4250-99cd-e87aeb832fd1"
      },
      "outputs": [],
      "source": [
        "# pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5b182ac-a57e-40ef-a996-63a5653e1434",
      "metadata": {
        "id": "f5b182ac-a57e-40ef-a996-63a5653e1434",
        "outputId": "4da47641-3995-4e81-cc6f-1d34b3c87d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:\n",
            "being that it is 12 p.m., I will call the special meeting to order. Can I have a mover and seconder for the adoption of the agenda, please? Councilor Fuel, Councilor Raulqui. Be it resolved that the agenda for January 10th special meeting of council be approved. Thank you. We are going to add on our question period that we have every council meeting. It should be right after the adoption of the agenda. Is there any further additions from council? All those in favor, carried four zero. I will now open up question period. So if there's anybody in the online gallery that has any questions, please just unmute yourself and put your hand up or unmute yourself and start talking and we'll get to your questions or comments. I'm not seeing any. So we will move on to the building sustainable communities grant applications. Can I have a mover and a seconder, please? Councilor Berdeen, Councilor Raulqui. Be it resolved that the municipality of Springfield formally apply for funding through the building sustainable communities program to defray project costs for the following projects. The Enola community club playground project with a budget of $75,000. The Springfield pathway system with a budget of $225,000. The Springfield trading posts with a budget of $50,000 and the Springfield aquatic and wellness center with a budget of 3,700,000. Thank you. I know that we've opened it up to apply for more projects this year. Hopefully we'll get some funding for each and every one of those. Is there any other comments from council? Councilor Raulqui. I just like to applaud our administration for moving forward with this. And as we know, the more, I guess, which would you call applications or projects or potential things that we can do for our community are for the better for us to apply for all. And then in the long run, see what it is that we end up with. So the more opportunity we have, the better it is for all. So thank you very much for, I know it's not always so easy to fill out grant applications and things like that. So I do appreciate all the work that they do. And we should hear back in a couple months on these applications. It's not clear. I know the deadline for application is January 17th, but they haven't indicated a response time. Okay. Any other comments or questions from council? All those in favor? Carried four, zero. We do have a council meeting at one. So we will adjourn until that time. Can I have a mover and seconder to adjourn, please? Councilor Fuel, Councilor Berdeen. All those in favor? Meeting adjourned.\n"
          ]
        }
      ],
      "source": [
        "# %load transcription.py\n",
        "# transcription.py\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "def transcribe_audio(audio_file_path, openai_client=None):\n",
        "    \"\"\"\n",
        "    Transcribes an audio file using OpenAI's Whisper API.\n",
        "\n",
        "    Args:\n",
        "        audio_file_path (str): The path to the audio file.\n",
        "        openai_client (openai.OpenAI, optional): An OpenAI client instance.\n",
        "                                                  If None, a new client will be created.\n",
        "\n",
        "    Returns:\n",
        "        str: The transcribed text.\n",
        "    \"\"\"\n",
        "    if openai_client is None:\n",
        "        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
        "    else:\n",
        "        client = openai_client\n",
        "\n",
        "    try:\n",
        "        with open(audio_file_path, \"rb\") as audio_file:\n",
        "            transcript = client.audio.transcriptions.create(\n",
        "                model=\"whisper-1\",\n",
        "                file=audio_file\n",
        "            )\n",
        "        return transcript.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error during transcription: {e}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage (for testing the transcription function)\n",
        "    load_dotenv()\n",
        "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "    if not openai_api_key:\n",
        "        print(\"OPENAI_API_KEY not found in .env file.\")\n",
        "    else:\n",
        "        audio_path = r\"C:\\Users\\dell\\Downloads\\newMeeting.mp3\"  # Replace with your audio file\n",
        "        if os.path.exists(audio_path):\n",
        "            transcription_text = transcribe_audio(audio_path)\n",
        "            if transcription_text:\n",
        "                print(\"Transcription:\")\n",
        "                print(transcription_text)\n",
        "        else:\n",
        "            print(f\"Audio file not found at: {audio_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d712458-43e3-4dd9-be05-5700d037595d",
      "metadata": {
        "id": "9d712458-43e3-4dd9-be05-5700d037595d"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "def abstract_summary_extraction(transcription):\n",
        "    response = OpenAI.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a highly skilled AI trained in language comprehension and summarization. I would like you to read the following text and summarize it into a concise abstract paragraph. Aim to retain the most important points, providing a coherent and readable summary that could help a person understand the main points of the discussion without needing to read the entire text. Please avoid unnecessary details or tangential points.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "def key_points_extraction(transcription):\n",
        "    response = OpenAI.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a proficient AI with a specialty in distilling information into key points. Based on the following text, identify and list the main points that were discussed or brought up. These should be the most important ideas, findings, or topics that are crucial to the essence of the discussion. Your goal is to provide a list that someone could read to quickly understand what was talked about.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "def action_item_extraction(transcription):\n",
        "    response = OpenAI.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are an AI expert in analyzing conversations and extracting action items. Please review the text and identify any tasks, assignments, or actions that were agreed upon or mentioned as needing to be done. These could be tasks assigned to specific individuals, or general actions that the group has decided to take. Please list these action items clearly and concisely.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "def sentiment_analysis(transcription):\n",
        "    response = OpenAI.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"As an AI with expertise in language and emotion analysis, your task is to analyze the sentiment of the following text. Please consider the overall tone of the discussion, the emotion conveyed by the language used, and the context in which words and phrases are used. Indicate whether the sentiment is generally positive, negative, or neutral, and provide brief explanations for your analysis where possible.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d97b4b5-ef40-422e-a291-8c6735730786",
      "metadata": {
        "id": "9d97b4b5-ef40-422e-a291-8c6735730786"
      },
      "outputs": [],
      "source": [
        "from docx import Document\n",
        "\n",
        "def save_as_docx(minutes, filename):\n",
        "    doc = Document()\n",
        "    for key, value in minutes.items():\n",
        "        # Replace underscores with spaces and capitalize each word for the heading\n",
        "        heading = ' '.join(word.capitalize() for word in key.split('_'))\n",
        "        doc.add_heading(heading, level=1)\n",
        "        doc.add_paragraph(value)\n",
        "        # Add a line break between sections\n",
        "        doc.add_paragraph()\n",
        "    doc.save(filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97884ac5-4b78-4af7-b32b-4336bb03e5c4",
      "metadata": {
        "id": "97884ac5-4b78-4af7-b32b-4336bb03e5c4"
      },
      "outputs": [],
      "source": [
        "#pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea904053-b2cd-416a-b110-6318770b3492",
      "metadata": {
        "id": "ea904053-b2cd-416a-b110-6318770b3492",
        "outputId": "e563ec02-8b48-4924-ff4f-51448b381d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from openai==0.28) (3.11.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from aiohttp->openai==0.28) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from aiohttp->openai==0.28) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from aiohttp->openai==0.28) (1.18.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\newenv\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
            "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.76.0\n",
            "    Uninstalling openai-1.76.0:\n",
            "      Successfully uninstalled openai-1.76.0\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4bd0daf-ee3a-437e-b607-f8ddb4cd8be8",
      "metadata": {
        "id": "b4bd0daf-ee3a-437e-b607-f8ddb4cd8be8",
        "outputId": "35ca24b8-dc85-42c1-c15b-1a97b283e096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'abstract_summary': 'A special council meeting was called at 12 p.m. where the agenda was adopted, including a question period. The council approved applying for funding for various community projects through the building sustainable communities program. Council members commended the administration for their efforts in pursuing these grants, emphasizing the importance of maximizing opportunities for community development. The meeting concluded with plans to reconvene for another council meeting at 1 p.m., with a motion to adjourn being passed.', 'key_points': 'Main Points Discussed:\\n1. Special meeting called to order at 12 p.m.\\n2. Adoption of the agenda approved with additions, including a question period.\\n3. Building Sustainable Communities grant applications discussed.\\n4. Projects for funding include Enola community club playground, Springfield pathway system, Springfield trading posts, and Springfield aquatic and wellness center.\\n5. Council commends administration for moving forward with grant applications.\\n6. Deadline for applications is January 17th, response time not specified.\\n7. Meeting adjourned with plans for a council meeting at 1 p.m.', 'action_items': 'Action items identified from the conversation:\\n1. Apply for funding through the building sustainable communities program for various projects.\\n2. Await responses on the grant applications submitted.\\n3. Prepare for the upcoming council meeting at 1 p.m.', 'sentiment': \"The sentiment of the text is generally positive. The language used throughout the discussion is formal and professional, indicating a sense of order and productivity. There is a focus on collaboration and community improvement through grant applications for various projects, which conveys a proactive and positive attitude towards enhancing the municipality. Council members express appreciation for the work done and show support for the initiatives, highlighting a sense of teamwork and dedication to the community's well-being. Overall, the tone is constructive and forward-looking, with a focus on progress and community development.\"}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from sentiment_analysis import *\n",
        "from transcription import *\n",
        "from save_as_docx import *\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "def meeting_minutes(transcription):\n",
        "    abstract_summary = abstract_summary_extraction(transcription_text)\n",
        "    key_points = key_points_extraction(transcription_text)\n",
        "    action_items = action_item_extraction(transcription_text)\n",
        "    sentiment = sentiment_analysis(transcription_text)\n",
        "    return {\n",
        "        'abstract_summary': abstract_summary,\n",
        "        'key_points': key_points,\n",
        "        'action_items': action_items,\n",
        "        'sentiment': sentiment\n",
        "    }\n",
        "\n",
        "# audio_file_path = r\"C:\\Users\\dell\\Downloads\\newMeeting.mp3\"\n",
        "# transcription = transcribe_audio(audio_file_path,OpenAI )\n",
        "minutes = meeting_minutes(transcription_text)\n",
        "print(minutes)\n",
        "\n",
        "save_as_docx(minutes, 'meeting_minutes1.docx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e89ae8-baae-463a-9a57-55b569c0973c",
      "metadata": {
        "id": "91e89ae8-baae-463a-9a57-55b569c0973c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}