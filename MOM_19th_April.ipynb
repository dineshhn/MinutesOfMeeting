{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshhn/MinutesOfMeeting/blob/gn/MOM_19th_April.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0gGVmVUIOIBQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gGVmVUIOIBQ",
        "outputId": "02e90910-ca81-43c1-9cdb-3570cafb868b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: nltk 3.8.1\n",
            "Uninstalling nltk-3.8.1:\n",
            "  Successfully uninstalled nltk-3.8.1\n",
            "Collecting nltk==3.8.1\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (4.67.1)\n",
            "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nltk\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nltk-3.8.1\n",
            "Tokenized: ['This', 'should', 'now', 'work', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y nltk\n",
        "!pip install --no-cache-dir nltk==3.8.1\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "from nltk import word_tokenize\n",
        "tokens = word_tokenize(\"This should now work.\")\n",
        "print(\"Tokenized:\", tokens)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wkNI-kyyI3XA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkNI-kyyI3XA",
        "outputId": "ced60a9d-1032-4c35-cb1b-a6fc269b60c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iqdU3-_GOIF9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqdU3-_GOIF9",
        "outputId": "2ba28049-f66d-401f-c711-952f7d500ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 3)) (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 4)) (2.6.0+cu124)\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 5)) (1.4)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 7)) (0.25.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 8)) (0.4.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 9)) (3.8.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 10)) (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r /content/drive/MyDrive/requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python->-r /content/drive/MyDrive/requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->-r /content/drive/MyDrive/requirements.txt (line 9)) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->-r /content/drive/MyDrive/requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->-r /content/drive/MyDrive/requirements.txt (line 9)) (2024.11.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score->-r /content/drive/MyDrive/requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score->-r /content/drive/MyDrive/requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (1.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2025.2)\n"
          ]
        }
      ],
      "source": [
        "# Install all the dependencies. Place any new installables into requirements.txt file.\n",
        "!pip install -r /content/drive/MyDrive/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pX3sOGA0OLV3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX3sOGA0OLV3",
        "outputId": "ba647663-47c2-4e1a-d6a2-9d07f7e7f72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.11/dist-packages (1.7.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "import time\n",
        "import nltk\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import plotly.graph_objects as go\n",
        "!pip install fpdf\n",
        "from fpdf import FPDF\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import plotly.io as pio\n",
        "\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2v-AuZ8s1-hT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v-AuZ8s1-hT",
        "outputId": "a11b46cc-4c22-4247-eef8-2805a9d394bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "transcription_pipelines = {\n",
        "    \"whisper-tiny.en\": pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=\"openai/whisper-tiny.en\",\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    ),\n",
        "    \"wav2vec2-bert\": pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=\"hf-audio/wav2vec2-bert-CV16-en\",\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    ),\n",
        "    \"openai/whisper-base.en\": pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=\"openai/whisper-base.en\",\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    )\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2-OSyhEni_zX",
      "metadata": {
        "id": "2-OSyhEni_zX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a178e1-e131-4a8f-e2f6-febd131dc635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "summarizer_pipelines = {\n",
        "    \"facebook/bart-large-cnn\": pipeline(\"summarization\", model=\"facebook/bart-large-cnn\"),\n",
        "    \"philschmid/bart-large-cnn-samsum\": pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")\n",
        "    # \"google/pegasus-xsum\": pipeline(\"summarization\", model=\"google/pegasus-xsum\"),\n",
        "    # \"facebook/bart-large-xsum\": pipeline(\"summarization\", model=\"facebook/bart-large-xsum\"),\n",
        "    # \"Falconsai/text_summarization\": pipeline(\"summarization\", model=\"Falconsai/text_summarization\")\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U kaleido"
      ],
      "metadata": {
        "id": "1mV9uvQcczym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca292f7b-163f-4b93-d2ba-92d18f6f2624"
      },
      "id": "1mV9uvQcczym",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.11/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4mVE6F8KNPQS",
      "metadata": {
        "id": "4mVE6F8KNPQS"
      },
      "outputs": [],
      "source": [
        "def transcribe_audio(file, model_name):\n",
        "\n",
        "    pipe = transcription_pipelines.get(model_name)\n",
        "\n",
        "    if pipe is None:\n",
        "        raise ValueError(\"Unsupported model\")\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "\n",
        "    if \"whisper\" in model_name:\n",
        "        result = pipe(file, return_timestamps=True)\n",
        "    else:\n",
        "        result = pipe(file)\n",
        "\n",
        "    end = time.time()\n",
        "    return result[\"text\"], f\"Transcription time: {end - start:.2f} seconds\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import textwrap\n",
        "import time\n",
        "import gc\n",
        "\n",
        "def summarize_text(text, model_name):\n",
        "\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    device_str = \"cuda\" if device == 0 else \"cpu\"\n",
        "    print(f\"Device set to use: {device_str}\")\n",
        "\n",
        "    try:\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cpu\")\n",
        "\n",
        "\n",
        "        summarizer = pipeline(\n",
        "            \"summarization\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            device=-1\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model {model_name}: {e}\")\n",
        "        return \"[Error loading model]\", 0.0\n",
        "\n",
        "\n",
        "    max_chunk_size = 900\n",
        "    chunks = textwrap.wrap(text, max_chunk_size)\n",
        "\n",
        "    final_summary = \"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"Summarizing chunk {i+1}/{len(chunks)} with {model_name}\")\n",
        "        try:\n",
        "            if chunk.strip() and len(chunk.strip().split()) > 5:\n",
        "                output = summarizer(\n",
        "                    chunk,\n",
        "                    max_length=130,\n",
        "                    min_length=30,\n",
        "                    do_sample=False\n",
        "                )\n",
        "                summary_text = output[0]['summary_text'].strip()\n",
        "\n",
        "                if \"CNN.com will feature\" not in summary_text:\n",
        "                    final_summary += summary_text + \" \"\n",
        "                else:\n",
        "                    print(\"Detected fallback summary, skipping.\")\n",
        "            else:\n",
        "                print(\"Skipping empty or short chunk.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error summarizing chunk with {model_name}: {e}\")\n",
        "            final_summary += \"[Error summarizing chunk] \"\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = round(end_time - start_time, 2)\n",
        "\n",
        "    return final_summary.strip(), elapsed_time\n"
      ],
      "metadata": {
        "id": "cUifkcTS_r1k"
      },
      "id": "cUifkcTS_r1k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def evaluate_summary(reference_text, summary):\n",
        "    nltk.download('punkt', quiet=True)\n",
        "\n",
        "\n",
        "    ref_tokens = nltk.word_tokenize(reference_text.lower())\n",
        "    pred_tokens = nltk.word_tokenize(summary.lower())\n",
        "\n",
        "\n",
        "    bleu = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=SmoothingFunction().method1)\n",
        "\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = scorer.score(reference_text, summary)\n",
        "\n",
        "\n",
        "    vectorizer = CountVectorizer(binary=True)\n",
        "    vectors = vectorizer.fit_transform([reference_text, summary]).toarray()\n",
        "    y_true, y_pred = vectors[0], vectors[1]\n",
        "\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return {\n",
        "        \"BLEU\": round(bleu, 2),\n",
        "        \"ROUGE1\": round(rouge_scores[\"rouge1\"].fmeasure, 2),\n",
        "        \"ROUGEL\": round(rouge_scores[\"rougeL\"].fmeasure, 2),\n",
        "        \"PRECISION\": round(precision, 2),\n",
        "        \"RECALL\": round(recall, 2),\n",
        "        \"F1\": round(f1, 2),\n",
        "        \"ACCURACY\": round(accuracy, 2),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "XTX7slmrpY4E"
      },
      "id": "XTX7slmrpY4E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gWitPCV8_eVH",
      "metadata": {
        "id": "gWitPCV8_eVH"
      },
      "outputs": [],
      "source": [
        "def show_loader(text):\n",
        "    return gr.update(value=f\" {text}...\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_action_items(action_items_by_model):\n",
        "    formatted = \"<h4>Action Items</h4>\"\n",
        "    for model, items in action_items_by_model.items():\n",
        "        formatted += f\"<b>{model}:</b><br>\"\n",
        "        if items:\n",
        "            formatted += \"<ul>\" + \"\".join(f\"<li>{item}</li>\" for item in items) + \"</ul>\"\n",
        "        else:\n",
        "            formatted += \"<i>No action items found.</i><br>\"\n",
        "    return formatted\n"
      ],
      "metadata": {
        "id": "bqmoUsPNbZBv"
      },
      "id": "bqmoUsPNbZBv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b05433",
      "metadata": {
        "id": "86b05433"
      },
      "outputs": [],
      "source": [
        "def extract_action_items(summary, keywords=None):\n",
        "    if not keywords:\n",
        "        keywords = [\"must\", \"should\", \"need to\", \"expanding\", \"revenue\", \"plan\", \"action\"]\n",
        "    keywords = [kw.lower() for kw in keywords]\n",
        "    sentences = summary.split(\". \")\n",
        "    return [s for s in sentences if any(kw in s.lower() for kw in keywords)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "import os\n",
        "import datetime\n",
        "def generate_pdf(transcription, results, graph_paths):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", 'B', 16)\n",
        "    pdf.cell(0, 10, \"Minutes of Meeting Report\", ln=True)\n",
        "\n",
        "\n",
        "    pdf.set_font(\"Arial\", 'B', 14)\n",
        "    pdf.cell(0, 10, \"Transcribed Text\", ln=True)\n",
        "    pdf.set_font(\"Arial\", size=11)\n",
        "    pdf.multi_cell(0, 10, transcription)\n",
        "\n",
        "\n",
        "    for model, data in results.items():\n",
        "        pdf.set_font(\"Arial\", 'B', 14)\n",
        "        pdf.cell(0, 10, f\"Summary - {model}\", ln=True)\n",
        "        pdf.set_font(\"Arial\", size=11)\n",
        "        pdf.multi_cell(0, 10, data['summary'])\n",
        "\n",
        "        pdf.set_font(\"Arial\", 'B', 12)\n",
        "        pdf.cell(0, 10, \"Action Items\", ln=True)\n",
        "        pdf.set_font(\"Arial\", size=11)\n",
        "        for item in data['actions']:\n",
        "            pdf.cell(5)\n",
        "            pdf.multi_cell(0, 10, f\"- {item}\")\n",
        "\n",
        "        pdf.set_font(\"Arial\", 'B', 12)\n",
        "        pdf.cell(0, 10, \"Evaluation Metrics\", ln=True)\n",
        "        pdf.set_font(\"Arial\", size=11)\n",
        "        for k, v in data[\"metrics\"].items():\n",
        "            pdf.cell(0, 10, f\"{k.upper()}: {v:.2f}\", ln=True)\n",
        "\n",
        "\n",
        "    titles = [\n",
        "        \"Bar Chart - Evaluation Metrics\",\n",
        "        f\"Pie Chart - {list(results.keys())[0]}\",\n",
        "        f\"Pie Chart - {list(results.keys())[1]}\" if len(results) > 1 else \"Pie Chart\",\n",
        "        \"Line Chart - Evaluation Metrics\",\n",
        "        \"Radar Chart - Evaluation Metrics\"\n",
        "    ]\n",
        "\n",
        "    for idx, path in enumerate(graph_paths):\n",
        "        if idx % 2 == 0:\n",
        "            pdf.add_page()\n",
        "\n",
        "        pdf.set_font(\"Arial\", 'B', 12)\n",
        "        pdf.cell(0, 10, titles[idx], ln=True)\n",
        "        pdf.image(path, w=180)\n",
        "        pdf.ln(5)\n",
        "\n",
        "    filename = f\"MoM_Report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf\"\n",
        "    file_path = os.path.join(os.getcwd(), filename)\n",
        "    pdf.output(file_path)\n",
        "    return file_path\n"
      ],
      "metadata": {
        "id": "Hv0s5I478d4m"
      },
      "id": "Hv0s5I478d4m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_graphs(results):\n",
        "    if not results or len(results) < 2:\n",
        "        return (gr.update(visible=False),) * 4\n",
        "\n",
        "\n",
        "    model_names = list(results.keys())\n",
        "    metrics = list(next(iter(results.values()))[\"metrics\"].keys())\n",
        "\n",
        "\n",
        "    fig1 = go.Figure()\n",
        "    for model in model_names:\n",
        "        fig1.add_trace(go.Bar(name=model,\n",
        "                              x=metrics,\n",
        "                              y=[results[model][\"metrics\"].get(m, 0.0) for m in metrics]))\n",
        "    fig1.update_layout(\n",
        "        title=\"Evaluation Metrics - Bar Chart\",\n",
        "        barmode='group',\n",
        "        xaxis_title=\"Metrics\",\n",
        "        yaxis_title=\"Score\",\n",
        "        yaxis=dict(range=[0, 1])\n",
        "    )\n",
        "\n",
        "\n",
        "    fig2 = go.Figure()\n",
        "    for model in model_names:\n",
        "        fig2.add_trace(go.Pie(\n",
        "            labels=metrics,\n",
        "            values=[results[model][\"metrics\"].get(m, 0.0) for m in metrics],\n",
        "            name=model,\n",
        "            hole=0.3,\n",
        "            title=model,\n",
        "            domain=dict(row=0, column=model_names.index(model))\n",
        "        ))\n",
        "    fig2.update_layout(title=\"Evaluation Metrics - Pie Chart\", grid=dict(rows=1, columns=len(model_names)))\n",
        "\n",
        "\n",
        "    fig3 = go.Figure()\n",
        "    for model in model_names:\n",
        "        fig3.add_trace(go.Scatter(\n",
        "            x=metrics,\n",
        "            y=[results[model][\"metrics\"].get(m, 0.0) for m in metrics],\n",
        "            mode=\"lines+markers\",\n",
        "            name=model\n",
        "        ))\n",
        "    fig3.update_layout(title=\"Evaluation Metrics - Line Chart\", yaxis=dict(range=[0, 1]))\n",
        "\n",
        "\n",
        "    fig4 = go.Figure()\n",
        "    for model in model_names:\n",
        "        values = [results[model][\"metrics\"].get(m, 0.0) for m in metrics]\n",
        "        values += values[:1]\n",
        "        fig4.add_trace(go.Scatterpolar(\n",
        "            r=values,\n",
        "            theta=metrics + [metrics[0]],\n",
        "            fill='toself',\n",
        "            name=model\n",
        "        ))\n",
        "    fig4.update_layout(\n",
        "        title=\"Evaluation Metrics - Radar Chart\",\n",
        "        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),\n",
        "        showlegend=True\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        gr.update(value=fig1, visible=True),\n",
        "        gr.update(value=fig2, visible=True),\n",
        "        gr.update(value=fig3, visible=True),\n",
        "        gr.update(value=fig4, visible=True)\n",
        "    )\n"
      ],
      "metadata": {
        "id": "H9hzaM4pq3K1"
      },
      "id": "H9hzaM4pq3K1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_graphs1(results):\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    models = list(results.keys())\n",
        "    metrics = list(results[models[0]][\"metrics\"].keys())\n",
        "\n",
        "    fig_bar = go.Figure()\n",
        "    fig_line = go.Figure()\n",
        "    for model in models:\n",
        "        values = list(results[model][\"metrics\"].values())\n",
        "        fig_bar.add_trace(go.Bar(name=model, x=metrics, y=values))\n",
        "        fig_line.add_trace(go.Scatter(name=model, x=metrics, y=values, mode='lines+markers'))\n",
        "\n",
        "    fig_bar.update_layout(title=\"Evaluation Metrics - Bar Chart\", barmode='group')\n",
        "    fig_line.update_layout(title=\"Evaluation Metrics - Line Chart\")\n",
        "\n",
        "\n",
        "    fig_radar = go.Figure()\n",
        "    for model in models:\n",
        "        values = list(results[model][\"metrics\"].values())\n",
        "        values += values[:1]\n",
        "        fig_radar.add_trace(go.Scatterpolar(r=values, theta=metrics + [metrics[0]], fill='toself', name=model))\n",
        "    fig_radar.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 1])), title=\"Radar Chart\")\n",
        "\n",
        "\n",
        "    fig_pie1 = go.Figure(go.Pie(\n",
        "        labels=metrics,\n",
        "        values=list(results[models[0]][\"metrics\"].values()),\n",
        "        title=f\"Pie Chart - {models[0]}\"\n",
        "    ))\n",
        "\n",
        "    fig_pie2 = go.Figure(go.Pie(\n",
        "        labels=metrics,\n",
        "        values=list(results[models[1]][\"metrics\"].values()),\n",
        "        title=f\"Pie Chart - {models[1]}\"\n",
        "    ))\n",
        "\n",
        "    return fig_bar, fig_pie1, fig_pie2, fig_line, fig_radar\n"
      ],
      "metadata": {
        "id": "cXqBJ8p6j68r"
      },
      "id": "cXqBJ8p6j68r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_format_outputs(file, trans_model, keywords, summarizer_models):\n",
        "    try:\n",
        "        print(\"=== PROCESS STARTED ===\")\n",
        "        print(f\"Selected Transcription Model: {trans_model}\")\n",
        "        print(f\"Selected Summarizer Models: {summarizer_models}\")\n",
        "\n",
        "\n",
        "        transcription, trans_time = transcribe_audio(file, trans_model)\n",
        "        print(\"Transcribed\")\n",
        "        yield transcription, \"Generating summary...\", \"Generating summary...\", f\"{trans_time}\", \"\", \"\", {}, None, \"Transcription complete.\"\n",
        "\n",
        "\n",
        "        results = {}\n",
        "        from concurrent.futures import ThreadPoolExecutor\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            futures = {\n",
        "                model: executor.submit(summarize_text, transcription, model)\n",
        "                for model in summarizer_models\n",
        "            }\n",
        "            for model, future in futures.items():\n",
        "                print(f\"Summarizing with: {model}\")\n",
        "                summary, summ_time_raw = future.result()\n",
        "\n",
        "\n",
        "                try:\n",
        "                    summ_time = float(summ_time_raw)\n",
        "                except:\n",
        "                    summ_time = 0.0\n",
        "\n",
        "                print(f\"Summary complete for: {model}\")\n",
        "                actions = extract_action_items(summary, keywords)\n",
        "                metrics = evaluate_summary(transcription, summary)\n",
        "                results[model] = {\n",
        "                    \"summary\": summary,\n",
        "                    \"actions\": actions,\n",
        "                    \"metrics\": metrics,\n",
        "                    \"times\": {\n",
        "                        \"transcription\": trans_time,\n",
        "                        \"summarization\": summ_time\n",
        "                    }\n",
        "                }\n",
        "\n",
        "\n",
        "        summary1 = results.get(summarizer_models[0], {}).get(\"summary\", \"\")\n",
        "        summary2 = results.get(summarizer_models[1], {}).get(\"summary\", \"\") if len(summarizer_models) > 1 else \"\"\n",
        "\n",
        "        formatted_actions = format_action_items({m: r[\"actions\"] for m, r in results.items()})\n",
        "\n",
        "\n",
        "        metric_keys = list(next(iter(results.values()))[\"metrics\"].keys())\n",
        "        metrics_html = \"<h4>Evaluation Metrics</h4><table border='1' cellpadding='6' style='border-collapse: collapse;'>\"\n",
        "        metrics_html += \"<tr><th>Metric</th>\" + \"\".join(f\"<th>{model}</th>\" for model in results.keys()) + \"</tr>\"\n",
        "        for metric in metric_keys:\n",
        "            metrics_html += \"<tr>\"\n",
        "            metrics_html += f\"<td><b>{metric}</b></td>\"\n",
        "            for model in results.keys():\n",
        "                val = results[model][\"metrics\"].get(metric, 0.0)\n",
        "                metrics_html += f\"<td>{val:.2f}</td>\"\n",
        "            metrics_html += \"</tr>\"\n",
        "        metrics_html += \"</table>\"\n",
        "\n",
        "\n",
        "        fig_bar, fig_pie1, fig_pie2, fig_line, fig_radar = show_graphs1(results)\n",
        "        graph_paths = []\n",
        "        for i, fig in enumerate([fig_bar, fig_pie1, fig_pie2, fig_line, fig_radar], start=1):\n",
        "            path = f\"graph_{i}.png\"\n",
        "            fig.write_image(path)\n",
        "            graph_paths.append(path)\n",
        "\n",
        "\n",
        "        summarization_times = \"\\n\".join([\n",
        "            f\"Summarization time ({model}): {results[model]['times']['summarization']:.2f} seconds\"\n",
        "            for model in results\n",
        "        ])\n",
        "        time_output = f\"{trans_time}\\n{summarization_times}\"\n",
        "\n",
        "\n",
        "        pdf_filename = generate_pdf(\n",
        "            transcription=transcription,\n",
        "            results=results,\n",
        "            graph_paths=graph_paths\n",
        "        )\n",
        "\n",
        "        yield transcription, summary1, summary2, time_output, formatted_actions, metrics_html, results, pdf_filename, \"Summarization complete.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error during processing: {str(e)}\"\n",
        "        print(\"EXCEPTION:\", error_msg)\n",
        "        yield error_msg, \"\", \"\", \"\", \"\", \"\", {}, None, \"Error\"\n"
      ],
      "metadata": {
        "id": "SlF_0JX1IXgW"
      },
      "id": "SlF_0JX1IXgW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import time\n",
        "import re\n",
        "import plotly.graph_objects as go\n",
        "from gradio.themes.soft import Soft\n",
        "from gradio.themes.utils import colors\n",
        "\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "\n",
        "custom_theme = Soft(primary_hue=colors.blue, font=[\"Inter\", \"sans-serif\"])\n",
        "\n",
        "\n",
        "def generate_comparison_table(eval_data):\n",
        "    html = \"\"\"\n",
        "    <h4>Comparison Table</h4>\n",
        "    <table border='1' style='border-collapse:collapse; width:100%; text-align:left;'>\n",
        "        <tr>\n",
        "            <th style='width:20%;'>Model</th>\n",
        "            <th style='width:60%;'>Summary</th>\n",
        "            <th style='width:20%;'>Metrics</th>\n",
        "        </tr>\n",
        "    \"\"\"\n",
        "    for model, data in eval_data.items():\n",
        "        summary = data.get('summary', '').replace('\\n', '<br>')\n",
        "        metrics = data.get('metrics', {})\n",
        "        metric_html = \"<br>\".join([f\"{k.upper()}: {v:.2f}\" for k, v in metrics.items()])\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <tr>\n",
        "            <td style='width:20%; vertical-align:top;'>{model}</td>\n",
        "            <td style='width:60%; vertical-align:top;'>{summary}</td>\n",
        "            <td style='width:20%; vertical-align:top;'>{metric_html}</td>\n",
        "        </tr>\n",
        "        \"\"\"\n",
        "    html += \"</table>\"\n",
        "    return html\n",
        "\n",
        "def update_summary_labels(selected_models):\n",
        "    label1 = f\"Summary - {selected_models[0]}\" if len(selected_models) > 0 else \"Summary - Model 1\"\n",
        "    label2 = f\"Summary - {selected_models[1]}\" if len(selected_models) > 1 else \"Summary - Model 2\"\n",
        "    visible2 = len(selected_models) > 1\n",
        "    return (\n",
        "        gr.Textbox.update(label=label1),\n",
        "        gr.Textbox.update(label=label2, visible=visible2)\n",
        "    )\n",
        "\n",
        "def live_audio(audio_type):\n",
        "    transcribe_audio = gr.Interface(\n",
        "                transcribe_audio,\n",
        "                gr.Audio(sources=\"microphone\"),\n",
        "                \"text\",\n",
        "            )\n",
        "    return transcribe_audio\n",
        "\n",
        "with gr.Blocks(theme=custom_theme) as demo:\n",
        "    gr.Markdown(\"### Minutes of Meeting\")\n",
        "\n",
        "    evaluation_state = gr.State()\n",
        "    summary_box_labels = gr.State({})\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "\n",
        "            audio_mode = gr.Radio(\n",
        "                choices=[\"Live recording\", \"Upload audio\"],\n",
        "                value=\"Upload audio\",\n",
        "                label=\"Select Audio Input Mode\"\n",
        "            )\n",
        "\n",
        "\n",
        "            live_audio_input = gr.Audio(type=\"filepath\", label=\"Record your audio\", visible=False, interactive=True, show_label=True)\n",
        "\n",
        "            file_input = gr.File(label=\"Upload your audio file\", visible=True)\n",
        "\n",
        "            def toggle_audio_inputs(mode):\n",
        "                return (\n",
        "                    gr.update(visible=(mode == \"Live recording\")),\n",
        "                    gr.update(visible=(mode == \"Upload audio\"))\n",
        "                )\n",
        "\n",
        "            audio_mode.change(\n",
        "                fn=toggle_audio_inputs,\n",
        "                inputs=audio_mode,\n",
        "                outputs=[live_audio_input, file_input]\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"Advanced Settings\", open=False):\n",
        "                trans_dropdown = gr.Dropdown(\n",
        "                    choices=[\"whisper-tiny.en\", \"wav2vec2-bert\", \"openai/whisper-base.en\"],\n",
        "                    label=\"Select Transcription Model\",\n",
        "                    value=\"whisper-tiny.en\",\n",
        "                )\n",
        "\n",
        "                summarizer_models = gr.CheckboxGroup(\n",
        "                    choices=[\n",
        "                        \"facebook/bart-large-cnn\",\n",
        "                        \"philschmid/bart-large-cnn-samsum\",\n",
        "                        \"google/pegasus-xsum\",\n",
        "                        \"facebook/bart-large-xsum\",\n",
        "                        \"Falconsai/text_summarization\"\n",
        "                    ],\n",
        "                    label=\"Select Summarizer Models (max 2)\",\n",
        "                    value=[\n",
        "                        \"facebook/bart-large-cnn\",\n",
        "                        \"philschmid/bart-large-cnn-samsum\"\n",
        "                    ],\n",
        "                    interactive=True\n",
        "                )\n",
        "\n",
        "                def limit_two_models(selection):\n",
        "                    return selection[:2] if len(selection) > 2 else selection\n",
        "\n",
        "                summarizer_models.change(\n",
        "                    fn=limit_two_models,\n",
        "                    inputs=summarizer_models,\n",
        "                    outputs=summarizer_models\n",
        "                )\n",
        "\n",
        "                keyword_input = gr.Textbox(\n",
        "                    label=\"Custom Keywords (comma-separated)\",\n",
        "                    placeholder=\"e.g. must, should, revenue, action\"\n",
        "                )\n",
        "\n",
        "            btn_all = gr.Button(\"Process All\")\n",
        "\n",
        "            with gr.Accordion(\"Evaluation Metric Graphs\", open=False):\n",
        "                with gr.Tabs():\n",
        "                    with gr.TabItem(\"Bar Chart\"):\n",
        "                        graph1 = gr.Plot(visible=False)\n",
        "                    with gr.TabItem(\"Pie Chart\"):\n",
        "                        graph2 = gr.Plot(visible=False)\n",
        "                    with gr.TabItem(\"Line Chart\"):\n",
        "                        graph3 = gr.Plot(visible=False)\n",
        "                    with gr.TabItem(\"Radar Chart\"):\n",
        "                        graph4 = gr.Plot(visible=False)\n",
        "\n",
        "            btn_show_graphs = gr.Button(\"Show Evaluation Metrics\")\n",
        "            btn_show_graphs.click(\n",
        "                fn=show_graphs,\n",
        "                inputs=[evaluation_state],\n",
        "                outputs=[graph1, graph2, graph3, graph4]\n",
        "            )\n",
        "\n",
        "            comparison_table = gr.HTML(label=\"Summary & Metric Comparison Table\")\n",
        "            btn_compare = gr.Button(\"Show Comparison Table\")\n",
        "            btn_compare.click(fn=generate_comparison_table, inputs=[evaluation_state], outputs=comparison_table)\n",
        "\n",
        "            output_plot = gr.HTML(label=\"Evaluation Plot (Static)\")\n",
        "            output_download = gr.File(label=\"Download Report\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            progress_box = gr.Textbox(label=\"Progress\", lines=2, interactive=False)\n",
        "            summary_boxes = gr.State({})\n",
        "\n",
        "            output_trans = gr.Textbox(label=\"Transcribed Text\", lines=10)\n",
        "            output_summ1 = gr.Textbox(label=\"Summary - Model 1\", lines=6, interactive=False)\n",
        "            output_summ2 = gr.Textbox(label=\"Summary - Model 2\", lines=6, interactive=False, visible=True)\n",
        "            output_time = gr.Textbox(label=\"Processing Time\", lines=2)\n",
        "            output_action = gr.HTML(label=\"Action Items\")\n",
        "            output_metrics = gr.HTML(label=\"Evaluation Metrics\")\n",
        "\n",
        "    def set_summary_visibility(selected_models):\n",
        "        visible = len(selected_models) > 1\n",
        "        return gr.Textbox.update(visible=visible)\n",
        "\n",
        "    summarizer_models.change(\n",
        "        fn=set_summary_visibility,\n",
        "        inputs=summarizer_models,\n",
        "        outputs=output_summ2\n",
        "    )\n",
        "\n",
        "    def route_audio(live_audio_path, file_audio_path, audio_mode, model, keywords, summarizers):\n",
        "\n",
        "        if \"Live recording\" in audio_mode and live_audio_path is not None:\n",
        "            file = live_audio_path\n",
        "        elif \"Upload audio\" in audio_mode and file_audio_path is not None:\n",
        "            file = file_audio_path\n",
        "        else:\n",
        "            yield \"Please provide an audio input.\", \"\", \"\", \"\", \"\", \"\", {}, None, \"Error\"\n",
        "            return\n",
        "\n",
        "        yield from process_and_format_outputs(file, model, keywords, summarizers)\n",
        "\n",
        "\n",
        "    btn_all.click(\n",
        "        fn=route_audio,\n",
        "        inputs=[live_audio_input, file_input, audio_mode, trans_dropdown, keyword_input, summarizer_models],\n",
        "        outputs=[\n",
        "            output_trans,\n",
        "            output_summ1,\n",
        "            output_summ2,\n",
        "            output_time,\n",
        "            output_action,\n",
        "            output_metrics,\n",
        "            evaluation_state,\n",
        "            output_download,\n",
        "            progress_box\n",
        "        ],\n",
        "        queue=True\n",
        "    )\n",
        "\n",
        "demo.queue().launch(debug=True, share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5VK9GXIQ33IW",
        "outputId": "023f5882-a6e1-4ef8-afeb-92237044b598"
      },
      "id": "5VK9GXIQ33IW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.25.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2024.12.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://641f283ab3b5fa6490.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://641f283ab3b5fa6490.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PROCESS STARTED ===\n",
            "Selected Transcription Model: whisper-tiny.en\n",
            "Selected Summarizer Models: ['facebook/bart-large-cnn', 'philschmid/bart-large-cnn-samsum']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed\n",
            "Device set to use: cpu\n",
            "Summarizing with: facebook/bart-large-cnn\n",
            "Device set to use: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarizing chunk 1/1 with philschmid/bart-large-cnn-samsum\n",
            "⚠️ Skipping empty or short chunk.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['lm_head.weight', 'model.encoder.embed_tokens.weight', 'model.shared.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading model facebook/bart-large-cnn: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.\n",
            "Summary complete for: facebook/bart-large-cnn\n",
            "Summarizing with: philschmid/bart-large-cnn-samsum\n",
            "Summary complete for: philschmid/bart-large-cnn-samsum\n",
            "=== PROCESS STARTED ===\n",
            "Selected Transcription Model: whisper-tiny.en\n",
            "Selected Summarizer Models: ['facebook/bart-large-cnn', 'philschmid/bart-large-cnn-samsum']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning:\n",
            "\n",
            "The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed\n",
            "Device set to use: cpu\n",
            "Device set to use: cpu\n",
            "Summarizing with: facebook/bart-large-cnn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['lm_head.weight', 'model.encoder.embed_tokens.weight', 'model.shared.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading model facebook/bart-large-cnn: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.\n",
            "Summary complete for: facebook/bart-large-cnn\n",
            "Summarizing with: philschmid/bart-large-cnn-samsum\n",
            "Error loading model philschmid/bart-large-cnn-samsum: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.\n",
            "Summary complete for: philschmid/bart-large-cnn-samsum\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://641f283ab3b5fa6490.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}