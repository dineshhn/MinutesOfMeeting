{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshhn/MinutesOfMeeting/blob/updated_mom/MinutesOfMeeting_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c1d4779",
      "metadata": {
        "id": "1c1d4779"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshhn/MinutesOfMeeting/blob/updated_mom/MinutesOfMeeting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wYpEjqlZXLgo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYpEjqlZXLgo",
        "outputId": "eb4cc02b-b3c5-4102-c39f-ae389c543c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d72f53d-32a9-4968-8086-dfa69eeccc71",
      "metadata": {
        "id": "8d72f53d-32a9-4968-8086-dfa69eeccc71",
        "outputId": "413fabfc-40da-4813-e6c8-f0a2a8868f4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 3)) (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 4)) (2.6.0+cu124)\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 5)) (1.4)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 7)) (0.25.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 8)) (0.4.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 9)) (3.9.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/requirements.txt (line 10)) (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r /content/drive/MyDrive/requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python->-r /content/drive/MyDrive/requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->-r /content/drive/MyDrive/requirements.txt (line 9)) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->-r /content/drive/MyDrive/requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->-r /content/drive/MyDrive/requirements.txt (line 9)) (2024.11.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score->-r /content/drive/MyDrive/requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score->-r /content/drive/MyDrive/requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/requirements.txt (line 1)) (2025.1)\n"
          ]
        }
      ],
      "source": [
        "# Install all the dependencies. Place any new installables into requirements.txt file.\n",
        "!pip install -r /content/drive/MyDrive/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88cabccf-048a-4115-b3f5-a73b2a59fd6a",
      "metadata": {
        "id": "88cabccf-048a-4115-b3f5-a73b2a59fd6a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f32084-3497-41b3-9f11-80f747e27c8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "81f32084-3497-41b3-9f11-80f747e27c8d",
        "outputId": "7f4f7512-de1d-419d-954e-80213261ae61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "# Select an audio file and read it:\n",
        "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
        "audio_sample = ds[0][\"audio\"]\n",
        "\n",
        "# Load the Whisper model with SDPA attention\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\", attn_implementation=\"sdpa\")\n",
        "\n",
        "# Enable static cache and compile the forward pass\n",
        "model.generation_config.cache_implementation = \"static\"\n",
        "model.forward = torch.compile(model.forward, mode=\"reduce-overhead\", fullgraph=True)\n",
        "\n",
        "# Use the model and processor to transcribe the audio:\n",
        "input_features = processor(\n",
        "    audio_sample[\"array\"], sampling_rate=audio_sample[\"sampling_rate\"], return_tensors=\"pt\"\n",
        ").input_features\n",
        "\n",
        "# Compile the forward pass\n",
        "for _ in range(2):\n",
        "    model.generate(input_features)\n",
        "\n",
        "# Generate token ids using compiled graph (fast!)\n",
        "predicted_ids = model.generate(input_features)\n",
        "\n",
        "# Decode token ids to text\n",
        "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "transcription[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a456af56-e418-4477-90c4-83bb6ffaf83a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a456af56-e418-4477-90c4-83bb6ffaf83a",
        "outputId": "c997793d-2aa5-472a-d388-e03824aa6da1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.04"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from transformers import AutoProcessor, Wav2Vec2BertForCTC\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\", trust_remote_code=True)\n",
        "dataset = dataset.sort(\"id\")\n",
        "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"hf-audio/wav2vec2-bert-CV16-en\")\n",
        "model = Wav2Vec2BertForCTC.from_pretrained(\"hf-audio/wav2vec2-bert-CV16-en\")\n",
        "\n",
        "# audio file is decoded on the fly\n",
        "inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# transcribe speech\n",
        "transcription = processor.batch_decode(predicted_ids)\n",
        "transcription[0]\n",
        "\n",
        "inputs[\"labels\"] = processor(text=dataset[0][\"text\"], return_tensors=\"pt\").input_ids\n",
        "\n",
        "# compute loss\n",
        "loss = model(**inputs).loss\n",
        "round(loss.item(), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80eec65d-c3f6-4307-8809-2fd3ecbc51c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80eec65d-c3f6-4307-8809-2fd3ecbc51c8",
        "outputId": "bb7f4387-f34c-45a3-e0a3-b74617378056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "whisper = pipeline(\"automatic-speech-recognition\", \"openai/whisper-large-v3\", torch_dtype=torch.float16, device=\"cuda:0\")\n",
        "\n",
        "# transcription = whisper(\"/content/drive/MyDrive/ColabNotebooks/EarningsCall.wav\", return_timestamps=True)\n",
        "\n",
        "# print(transcription[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepspeech"
      ],
      "metadata": {
        "id": "cYnU9_n6QENN",
        "outputId": "aff638f2-402a-4afd-a863-c013f5e65166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cYnU9_n6QENN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement deepspeech (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for deepspeech\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LkXV31_XHnU3"
      },
      "id": "LkXV31_XHnU3"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Transcription & Summary Function ---\n",
        "def transcribe_audio_with_whisper(file):\n",
        "    whisper = pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        \"openai/whisper-large-v3\",\n",
        "        torch_dtype=torch.float16,\n",
        "        device=\"cuda:0\"\n",
        "    )\n",
        "\n",
        "    start_trans = time.time()\n",
        "    transcription = whisper(file, return_timestamps=True)\n",
        "    end_trans = time.time()\n",
        "    full_transcription = transcription[\"text\"]\n",
        "    trans_time = f\"Transcription time: {end_trans - start_trans:.2f} seconds\"\n",
        "\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    start_summ = time.time()\n",
        "    summary = summarizer(full_transcription, max_length=130, min_length=30, do_sample=False)[0][\"summary_text\"]\n",
        "    end_summ = time.time()\n",
        "    summ_time = f\"Summarization time: {end_summ - start_summ:.2f} seconds\"\n",
        "\n",
        "    return full_transcription, summary, trans_time, summ_time"
      ],
      "metadata": {
        "id": "yjp_TGJ9AUtA"
      },
      "id": "yjp_TGJ9AUtA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dispatcher\n",
        "def process_based_on_selection(file, choice):\n",
        "    if choice == \"Whisper-large-v3\":\n",
        "        return transcribe_audio_with_whisper(file)\n",
        "    else:\n",
        "        return \"Invalid model\", \"Invalid model\", \"\", \"\""
      ],
      "metadata": {
        "id": "aCB2dAxAAU0v"
      },
      "id": "aCB2dAxAAU0v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_action_items(full_transcription, keywords):\n",
        "    # Use default keywords if none provided\n",
        "    if not keywords:\n",
        "        keywords = [\n",
        "            \"must\", \"should\", \"need to\", \"investing\", \"expanding\",\n",
        "            \"diversifying\", \"enhancing\", \"revenue\", \"risk\", \"loss\"\n",
        "        ]\n",
        "    else:\n",
        "        keywords = [kw.strip().lower() for kw in keywords.split(\",\")]\n",
        "\n",
        "    # Split transcription into sentences\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', full_transcription)\n",
        "\n",
        "    # Filter sentences containing any keyword\n",
        "    action_items = [\n",
        "        sentence for sentence in sentences\n",
        "        if any(keyword in sentence.lower() for keyword in keywords)\n",
        "    ]\n",
        "\n",
        "    return action_items\n"
      ],
      "metadata": {
        "id": "F3pRBIPCjbxL"
      },
      "id": "F3pRBIPCjbxL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_action_items(file, choice, keywords):\n",
        "    transcription, _, _, _ = process_based_on_selection(file, choice)\n",
        "\n",
        "    start_action = time.time()\n",
        "    action_items = extract_action_items(transcription, keywords)\n",
        "    end_action = time.time()\n",
        "    action_time = f\"Action item extraction time: {end_action - start_action:.2f} seconds\"\n",
        "\n",
        "    if action_items:\n",
        "        formatted_actions = \"\\n\".join([f\"{i+1}. {item}\" for i, item in enumerate(action_items)])\n",
        "    else:\n",
        "        formatted_actions = \"No action items found.\"\n",
        "\n",
        "    return f\"{formatted_actions}\\n\\n{action_time}\"\n"
      ],
      "metadata": {
        "id": "ymPLDKgtjb4L"
      },
      "id": "ymPLDKgtjb4L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_format_outputs(file, choice, keywords):\n",
        "    transcription, summary, trans_time, summ_time = process_based_on_selection(file, choice)\n",
        "\n",
        "    # Format transcription and summary\n",
        "    trans_with_time = f\"{transcription}\\n\\n{trans_time}\"\n",
        "    summ_with_time = f\"{summary}\\n\\n{summ_time}\"\n",
        "    both_times = f\"{trans_time}\\n{summ_time}\"\n",
        "\n",
        "    # Action items\n",
        "    start_action = time.time()\n",
        "    action_items = extract_action_items(transcription, keywords)\n",
        "    end_action = time.time()\n",
        "    action_time = f\"Action item extraction time: {end_action - start_action:.2f} seconds\"\n",
        "\n",
        "    if action_items:\n",
        "        formatted_actions = \"\\n\".join([f\"{i+1}. {item}\" for i, item in enumerate(action_items)])\n",
        "    else:\n",
        "        formatted_actions = \"No action items found.\"\n",
        "    actions_with_time = f\"{formatted_actions}\\n\\n{action_time}\"\n",
        "\n",
        "    return trans_with_time, summ_with_time, both_times, actions_with_time\n"
      ],
      "metadata": {
        "id": "ZC8cCL8sjb_f"
      },
      "id": "ZC8cCL8sjb_f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_txt_report(transcription, summary, trans_time, summ_time, action_items_text, metrics_text):\n",
        "#     report = (\n",
        "#         \" Minutes of Meeting Report\\n\"\n",
        "#         \"============================\\n\\n\"\n",
        "#         f\"Transcription:\\n{transcription}\\n\\n\"\n",
        "#         f\"{trans_time}\\n\\n\"\n",
        "#         f\"Summary:\\n{summary}\\n\\n\"\n",
        "#         f\"{summ_time}\\n\\n\"\n",
        "#         f\" Action Items:\\n{action_items_text}\\n\\n\"\n",
        "#         f\" Evaluation Metrics:\\n{metrics_text}\\n\"\n",
        "#     )\n",
        "\n",
        "#     # Save to file\n",
        "#     file_path = \"/mnt/data/minutes_report.txt\"\n",
        "#     with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "#         f.write(report)\n",
        "\n",
        "#     return file_path  # Return the path so it can be used as a downloadable file\n"
      ],
      "metadata": {
        "id": "ia0CXD2tHGDx"
      },
      "id": "ia0CXD2tHGDx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr # Import the gradio library and alias it as 'gr'\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import time\n",
        "import re\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### Minutes of meeting\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            file_input = gr.File(label=\"Upload your audio file\")\n",
        "            dropdown = gr.Dropdown(choices=[\"Whisper-large-v3\", \"Facebook - Wav2vec2\", \"Whisper-Small\", \"Mozzilla - Deepspeech\", \"Google - Speech Recognition\"], label=\"Select Model\")\n",
        "            keyword_input = gr.Textbox(\n",
        "                label=\"Custom Action Item Keywords (comma-separated)\",\n",
        "                placeholder=\"e.g. must, should, expanding, revenue\"\n",
        "            )\n",
        "            with gr.Row():\n",
        "                btn_trans = gr.Button(\"Transcribe the uploaded file\")\n",
        "                btn_summ = gr.Button(\"Generate the summary\")\n",
        "            #btn_time = gr.Button(\"Show Both Timings\")\n",
        "            btn_action = gr.Button(\"Extract Action Items\")\n",
        "            btn_all = gr.Button(\"Process All\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            output_trans = gr.Textbox(label=\"Transcribed Text\", lines=10)\n",
        "            output_summ = gr.Textbox(label=\"Summary\", lines=6)\n",
        "            output_time = gr.Textbox(label=\"Processing time\", lines=2)\n",
        "            output_action = gr.Textbox(label=\"Action Items\", lines=10)\n",
        "            output_metrics = gr.Textbox(label=\"Evaluation Metrics\", lines=10)\n",
        "\n",
        "\n",
        "    # Individual buttons\n",
        "    btn_trans.click(\n",
        "        fn=lambda file, choice: f\"{process_based_on_selection(file, choice)[0]}\\n\\n{process_based_on_selection(file, choice)[2]}\",\n",
        "        inputs=[file_input, dropdown],\n",
        "        outputs=output_trans\n",
        "    )\n",
        "\n",
        "    btn_summ.click(\n",
        "        fn=lambda file, choice: f\"{process_based_on_selection(file, choice)[1]}\\n\\n{process_based_on_selection(file, choice)[3]}\",\n",
        "        inputs=[file_input, dropdown],\n",
        "        outputs=output_summ\n",
        "    )\n",
        "\n",
        "    # btn_time.click(\n",
        "    #     fn=lambda file, choice: f\"{process_based_on_selection(file, choice)[2]}\\n{process_based_on_selection(file, choice)[3]}\",\n",
        "    #     inputs=[file_input, dropdown],\n",
        "    #     outputs=output_time\n",
        "    # )\n",
        "\n",
        "    btn_action.click(\n",
        "        fn=process_action_items,\n",
        "        inputs=[file_input, dropdown, keyword_input],\n",
        "        outputs=output_action\n",
        "    )\n",
        "\n",
        "    # Combined \"Process All\" button\n",
        "    btn_all.click(\n",
        "        fn=process_and_format_outputs,\n",
        "        inputs=[file_input, dropdown, keyword_input],\n",
        "        outputs=[output_trans, output_summ, output_time, output_action, output_metrics]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hJsJPRW8jcG0",
        "outputId": "3d561d82-2f3a-4f85-9a5e-51e6df21a89d"
      },
      "id": "hJsJPRW8jcG0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.23.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2024.12.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://da9a9a92961aa08c12.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://da9a9a92961aa08c12.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def evaluate_summary(transcription, summary):\n",
        "    # Tokenize\n",
        "    ref_tokens = nltk.word_tokenize(transcription.lower())\n",
        "    gen_tokens = nltk.word_tokenize(summary.lower())\n",
        "\n",
        "    # BLEU Score\n",
        "    bleu = sentence_bleu([ref_tokens], gen_tokens)\n",
        "\n",
        "    # Align lengths for token-wise metrics\n",
        "    min_len = min(len(ref_tokens), len(gen_tokens))\n",
        "    y_true = ref_tokens[:min_len]\n",
        "    y_pred = gen_tokens[:min_len]\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # ROUGE Score\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = scorer.score(transcription, summary)\n",
        "    rouge1 = rouge_scores['rouge1'].fmeasure\n",
        "    rougel = rouge_scores['rougeL'].fmeasure\n",
        "\n",
        "    metrics = (\n",
        "        f\"Evaluation Metrics:\\n\\n\"\n",
        "        f\"BLEU Score: {bleu:.4f}\\n\"\n",
        "        f\"Precision: {precision:.4f}\\n\"\n",
        "        f\"Recall: {recall:.4f}\\n\"\n",
        "        f\"F1 Score: {f1:.4f}\\n\"\n",
        "        f\"Accuracy: {accuracy:.4f}\\n\"\n",
        "        f\"ROUGE-1: {rouge1:.4f}\\n\"\n",
        "        f\"ROUGE-L: {rougel:.4f}\"\n",
        "    )\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPCGX3wfEINx",
        "outputId": "9d903d04-ef7a-419c-bb53-046a94d9139e"
      },
      "id": "oPCGX3wfEINx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_format_outputs(file, choice, keywords):\n",
        "    transcription, summary, trans_time, summ_time = process_based_on_selection(file, choice)\n",
        "\n",
        "    trans_with_time = f\"{transcription}\\n\\n{trans_time}\"\n",
        "    summ_with_time = f\"{summary}\\n\\n{summ_time}\"\n",
        "    both_times = f\"{trans_time}\\n{summ_time}\"\n",
        "\n",
        "    # Action items\n",
        "    start_action = time.time()\n",
        "    action_items = extract_action_items(transcription, keywords)\n",
        "    end_action = time.time()\n",
        "    action_time = f\"Action item extraction time: {end_action - start_action:.2f} seconds\"\n",
        "\n",
        "    if action_items:\n",
        "        formatted_actions = \"\\n\".join([f\"{i+1}. {item}\" for i, item in enumerate(action_items)])\n",
        "    else:\n",
        "        formatted_actions = \"No action items found.\"\n",
        "    actions_with_time = f\"{formatted_actions}\\n\\n{action_time}\"\n",
        "\n",
        "    # Evaluate summary\n",
        "    evaluation_results = evaluate_summary(transcription, summary)\n",
        "\n",
        "    return trans_with_time, summ_with_time, both_times, actions_with_time, evaluation_results\n"
      ],
      "metadata": {
        "id": "FTOgKAUEEIXm"
      },
      "id": "FTOgKAUEEIXm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}